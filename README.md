# ğŸ—¿ newsgroup_semantics

## Manifold Learning & Semantic Discovery Pipeline

Resolving high-dimensional sparsity through optimized latent semantic analysis.

---

## ğŸ›ï¸ Architecture

This repository benchmarks **Classical (TF-IDF)** vs. **Embedding-based (Doc2Vec)** architectures for **unsupervised topic discovery**.

It explicitly rejects the _â€œblobâ€ artifacts_ common in naÃ¯ve dimensionality-reduction pipelines by enforcing **dense feature initialization before manifold projection**.

### âš¡ Optimized Pipeline

### ğŸ§  Latent Discovery

- Compresses **16,000+ sparse dimensions**
- Produces **50 dense semantic features**
- Preserves global structure before non-linear projection

### ğŸ“ Modular Design

- Clean separation of concerns:
  - **ETL**
  - **Vectorization**
  - **Visualization**
- Production-grade utilities isolated from exploratory notebooks

---

## ğŸ“‰ Visual Dominance

### Baseline vs. Optimization

> We donâ€™t accept noise.  
> We force separation.

| Baseline (NaÃ¯ve t-SNE)   | Optimized (SVD-Initialized) |
| ------------------------ | --------------------------- |
| Messy starburst artifact | Clear semantic islands      |

**Observation:**  
SVD initialization successfully _unfolds the manifold_, separating **Hockey (Cyan)** from **Baseball (Pink)** where raw Euclidean distance failed. Check notebook for more information.

---

## ğŸ“‚ Repository Structure

```plaintext
nlp-clustering-benchmarks/
â”œâ”€â”€ data/                  # ğŸ”’ Gitignored raw assets
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_baseline.ipynb  # ğŸ· TF-IDF & SVD Optimization
â”‚   â””â”€â”€ 02_research.ipynb  # ğŸš§ Doc2Vec Experimentation (Local)
â”œâ”€â”€ src/                   # ğŸ—ï¸ Production-grade modules
â”‚   â””â”€â”€ utils.py           #    ETL & Preprocessing engine
â””â”€â”€ requirements.txt       # ğŸ’¼ Dependency lockfile
```

## ğŸš€ Quick Start

Assert dominance over your environment:

```bash
# 1. Clone the repo

git clone https://github.com/YOUR_USERNAME/nlp-clustering-benchmarks.git

# 2. Install dependencies

pip install -r requirements.txt

# 3. Execute the pipeline

jupyter notebook notebooks/01_baseline.ipynb

```
